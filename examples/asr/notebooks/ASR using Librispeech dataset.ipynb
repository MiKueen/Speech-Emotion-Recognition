{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeMo's \"core\" package\n",
    "import nemo\n",
    "# NeMo's ASR collection\n",
    "import nemo_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Neural Factory\n",
    "# It creates log files and tensorboard writers for us among other functions\n",
    "nf = nemo.core.NeuralModuleFactory(\n",
    "    log_dir='jasper12x1SEP',\n",
    "    create_tb_writer=True)\n",
    "tb_writer = nf.tb_writer\n",
    "logger = nf.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our training manifest\n",
    "train_dataset = \"/NeMo/examples/asr/data/train_clean_100.json\"\n",
    "\n",
    "# Path to our validation manifest\n",
    "eval_datasets = \"/NeMo/examples/asr/data/dev_clean.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jasper Model definition\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "# Here we will be using separable convolutions\n",
    "# with 12 blocks (k=12 repeated once r=1 from the picture above)\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(\"/NeMo/examples/asr/configs/quartznet15x5.yaml\") as f:\n",
    "    jasper_model_definition = yaml.load(f)\n",
    "labels = jasper_model_definition['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate neural modules\n",
    "data_layer = nemo_asr.AudioToTextDataLayer(\n",
    "    manifest_filepath=train_dataset,\n",
    "    labels=labels, batch_size=32)\n",
    "data_layer_val = nemo_asr.AudioToTextDataLayer(\n",
    "    manifest_filepath=eval_datasets,\n",
    "    labels=labels, batch_size=32, shuffle=False)\n",
    "\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor()\n",
    "spec_augment = nemo_asr.SpectrogramAugmentation(rect_masks=5)\n",
    "\n",
    "jasper_encoder = nemo_asr.JasperEncoder(\n",
    "    feat_in=64,\n",
    "    **jasper_model_definition['JasperEncoder'])\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC(\n",
    "    feat_in=1024, num_classes=len(labels))\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(labels))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()\n",
    "\n",
    "jasper_encoder.restore_from(\"./quartznet15x5/JasperEncoder-STEP-247400.pt\")\n",
    "jasper_decoder.restore_from(\"./quartznet/15x5/JasperDecoderForCTC-STEP-247400.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DAG (Model)\n",
    "audio_signal, audio_signal_len, transcript, transcript_len = data_layer()\n",
    "processed_signal, processed_signal_len = data_preprocessor(\n",
    "    input_signal=audio_signal, length=audio_signal_len)\n",
    "aug_signal = spec_augment(input_spec=processed_signal)\n",
    "encoded, encoded_len = jasper_encoder(\n",
    "    audio_signal=aug_signal, length=processed_signal_len)\n",
    "log_probs = jasper_decoder(encoder_output=encoded)\n",
    "predictions = greedy_decoder(log_probs=log_probs)\n",
    "loss = ctc_loss(\n",
    "    log_probs=log_probs, targets=transcript,\n",
    "    input_length=encoded_len, target_length=transcript_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation DAG (Model)\n",
    "# We need to instantiate additional data layer neural module\n",
    "# for validation data\n",
    "audio_signal_v, audio_signal_len_v, transcript_v, transcript_len_v = data_layer_val()\n",
    "processed_signal_v, processed_signal_len_v = data_preprocessor(\n",
    "    input_signal=audio_signal_v, length=audio_signal_len_v)\n",
    "# Note that we are not using data-augmentation in validation DAG\n",
    "encoded_v, encoded_len_v = jasper_encoder(\n",
    "    audio_signal=processed_signal_v, length=processed_signal_len_v)\n",
    "log_probs_v = jasper_decoder(encoder_output=encoded_v)\n",
    "predictions_v = greedy_decoder(log_probs=log_probs_v)\n",
    "loss_v = ctc_loss(\n",
    "    log_probs=log_probs_v, targets=transcript_v,\n",
    "    input_length=encoded_len_v, target_length=transcript_len_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper functions are needed to print and compute various metrics\n",
    "# such as word error rate and log them into tensorboard\n",
    "# they are domain-specific and are provided by NeMo's collections\n",
    "from nemo_asr.helpers import monitor_asr_train_progress, \\\n",
    "    process_evaluation_batch, process_evaluation_epoch\n",
    "from functools import partial\n",
    "# Callback to track loss and print predictions during training\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tb_writer=tb_writer,\n",
    "    # Define the tensors that you want SimpleLossLoggerCallback to\n",
    "    # operate on\n",
    "    # Here we want to print our loss, and our word error rate which\n",
    "    # is a function of our predictions, transcript, and transcript_len\n",
    "    tensors=[loss, predictions, transcript, transcript_len],\n",
    "    # To print logs to screen, define a print_func\n",
    "    print_func=partial(\n",
    "        monitor_asr_train_progress,\n",
    "        labels=labels,\n",
    "        logger=logger)\n",
    "    )\n",
    "\n",
    "saver_callback = nemo.core.CheckpointCallback(\n",
    "    folder=\"./\",\n",
    "    # Set how often we want to save checkpoints\n",
    "    step_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRO TIP: while you can only have 1 train DAG, you can have as many\n",
    "# val DAGs and callbacks as you want. This is useful if you want to monitor\n",
    "# progress on more than one val dataset at once (say LibriSpeech dev clean\n",
    "# and dev other)\n",
    "eval_callback = nemo.core.EvaluatorCallback(\n",
    "    eval_tensors=[loss_v, predictions_v, transcript_v, transcript_len_v],\n",
    "    # how to process evaluation batch - e.g. compute WER\n",
    "    user_iter_callback=partial(\n",
    "        process_evaluation_batch,\n",
    "        labels=labels\n",
    "        ),\n",
    "    # how to aggregate statistics (e.g. WER) for the evaluation epoch\n",
    "    user_epochs_done_callback=partial(\n",
    "        process_evaluation_epoch, tag=\"DEV-CLEAN\", logger=logger\n",
    "        ),\n",
    "    eval_step=500,\n",
    "    tb_writer=tb_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training using your Neural Factory\n",
    "# Once this \"action\" is called data starts flowing along train and eval DAGs\n",
    "# and computations start to happen\n",
    "nf.train(\n",
    "    # Specify the loss to optimize for\n",
    "    tensors_to_optimize=[loss],\n",
    "    # Specify which callbacks you want to run\n",
    "    callbacks=[train_callback, eval_callback, saver_callback],\n",
    "    # Specify what optimizer to use\n",
    "    optimizer=\"novograd\",\n",
    "    # Specify optimizer parameters such as num_epochs and lr\n",
    "    optimization_params={\n",
    "        \"num_epochs\": 50, \"lr\": 0.02, \"weight_decay\": 1e-4\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
